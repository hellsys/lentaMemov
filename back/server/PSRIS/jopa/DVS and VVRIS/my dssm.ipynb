{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open('time data and backups/id_pubs.json') as file:\n",
    "    # id_pubs = {}\n",
    "    # for pubs in user_pub.values():\n",
    "    #     if pubs:\n",
    "    #         for pub in pubs:\n",
    "    #             if pub not in id_pubs.keys():\n",
    "    #                 id_pubs[pub] = k\n",
    "    #                 k += 1\n",
    "    # json.dump(id_pubs,file)\n",
    "    id_pubs = json.load(file)\n",
    "    # print(len(id_pubs))\n",
    "k = 0\n",
    "with open('time data and backups/id_users.json') as file:\n",
    "    # id_users = {}\n",
    "    # for user in user_pub.keys():a\n",
    "    #     id_users[user] = k\n",
    "    #     k += 1\n",
    "    # json.dump(id_users,file)\n",
    "    id_users = json.load(file)\n",
    "    # print(len(id_users))\n",
    "shape = len(id_users.keys()),len(id_pubs.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "arr = sp.sparse.load_npz('time data and backups/matrix big.npz')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class DSSM(tf.Module):\n",
    "    def __init__(self,components):\n",
    "        super().__init__()\n",
    "\n",
    "        self.components = components\n",
    "\n",
    "        self.U = None\n",
    "        self.I = None\n",
    "\n",
    "        self.opt = tf.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "        self.fl_init = False\n",
    "    @tf.function\n",
    "    def loss_u(self,variables,y_true):\n",
    "        y = variables@self.I\n",
    "        loss = tf.sqrt(tf.losses.mean_squared_error(y_true,y))\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def loss_i(self,variables,y_true):\n",
    "        y = self.U@variables\n",
    "        loss = tf.sqrt(tf.losses.mean_squared_error(y_true,y))\n",
    "        return loss\n",
    "\n",
    "    def __call__(self, data=None,mean=True,*args, **kwargs):\n",
    "        if data is None:\n",
    "            return self.U@self.I\n",
    "        if mean:\n",
    "            return np.mean(data-self.U@self.I)\n",
    "        return data-self.U@self.I\n",
    "\n",
    "    def fit(self, data, iterations=4, parralel_U = 1, parralel_I=1,batch=1000):\n",
    "        data_sparse = type(data) == sp.sparse._csr.csr_matrix\n",
    "        for epoch in range(iterations):\n",
    "\n",
    "            print('epoch: ',epoch)\n",
    "            if not self.fl_init:\n",
    "                self.U = tf.Variable(np.random.uniform(0,1,(data.shape[0],self.components)))\n",
    "                self.I = tf.Variable(np.random.uniform(0,1,(self.components,data.shape[1])))\n",
    "                self.fl_init = True\n",
    "                # print(self().shape)\n",
    "            if epoch % 2 == 0:\n",
    "                for i in range(data.shape[0]//parralel_U):\n",
    "                    # for k in range(data.shape[1]//batch):\n",
    "                        ids = tf.random.uniform((1000,),0,data.shape[1],dtype=tf.int32)\n",
    "\n",
    "                        variables = tf.Variable(self.U[(i)*parralel_U:(i+1)*parralel_U],name=f'VarBatch{parralel_U}')\n",
    "\n",
    "                        if data_sparse:\n",
    "                            y_true = tf.constant(data[i*parralel_U:(i+1)*parralel_U,ids].toarray())\n",
    "                        else:\n",
    "                            y_true = tf.constant(data[i*parralel_U:(i+1)*parralel_U,ids])\n",
    "\n",
    "                        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "                            tape.watch(variables)\n",
    "                            loss = self.loss_u(variables,y_true)\n",
    "                        # print('loss', loss)\n",
    "                        gradients = tape.gradient(loss,variables)\n",
    "                        # print('grads: ',gradients)\n",
    "                        # if batch_U == 1:\n",
    "                        self.opt.apply_gradients(zip([gradients],[variables]))\n",
    "                        # else:\n",
    "                        #     self.opt.apply_gradients(zip(gradients,[variables]))\n",
    "\n",
    "                        self.U[(i)*parralel_U:(i+1)*parralel_U].assign(variables)\n",
    "\n",
    "            else:\n",
    "                for i in range(data.shape[0] // parralel_I):\n",
    "                    # for k in range(data.shape[1]//batch):\n",
    "                        ids = list(np.random.randint(0,data.shape[0],(batch,)))\n",
    "                        variables = tf.Variable(self.I[(i) * parralel_I:(i + 1) * parralel_I], name=f'VarBatch{parralel_I}')\n",
    "                        # print('v shape', variables.shape)\n",
    "                        if data_sparse:\n",
    "                            y_true = tf.constant(data[ids, i * parralel_I:(i + 1) * parralel_I].toarray())\n",
    "                        else:\n",
    "                            y_true = tf.constant(data[ids, i * parralel_I:(i + 1) * parralel_I])\n",
    "\n",
    "                        with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "                            tape.watch(variables)\n",
    "                            loss = self.loss_i(variables,y_true)\n",
    "                        # print('loss', loss)\n",
    "                        gradients = tape.gradient(loss,variables)\n",
    "                        # print('grads: ',gradients)\n",
    "                        # if batch_I == 1:\n",
    "                        #     self.opt.apply_gradients(zip([gradients],[variables]))\n",
    "                        # else:\n",
    "                        #     self.opt.apply_gradients(zip(gradients,variables))\n",
    "                        self.opt.apply_gradients(zip([gradients],[variables]))\n",
    "\n",
    "                        self.I[:, (i) * parralel_I:(i + 1) * parralel_I].assign(variables)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "data = arr[:25000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_big = DSSM(128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_big.fit(data,4,1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInternalError\u001B[0m                             Traceback (most recent call last)",
      "Input \u001B[1;32mIn [19]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel_big\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36mDSSM.fit\u001B[1;34m(self, data, iterations, parralel_U, parralel_I, batch)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfl_init:\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mU \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mVariable(np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m1\u001B[39m,(data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m],\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomponents)))\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mI \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mVariable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muniform\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomponents\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfl_init \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# print(self().shape)\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\NewML\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\PycharmProjects\\NewML\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInternalError\u001B[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "li_t = tf.random.uniform((100,10),0,10000,dtype=tf.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "indeces = tf.random.uniform((10,),0,1000,dtype=tf.int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10, 10), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(li_t,indeces,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<10x1117971 sparse matrix of type '<class 'numpy.float64'>'\n\twith 572 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[indeces]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}